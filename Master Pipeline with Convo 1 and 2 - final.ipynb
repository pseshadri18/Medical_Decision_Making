{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master (Leave-One-Out) Pipeline\n",
    "\n",
    "This is our master pipeline, which takes us through text pre-processing, LDA topic modeling, leave-one-out cross-validation, and model evaluation.\n",
    "\n",
    "Our analysis focused on comparing three models:\n",
    "- a model with baseline measures\n",
    "- a model with baseline measures and topic distributions\n",
    "- a model with baseline measures and physician's advice\n",
    "\n",
    "We want to show that the model with topic distributions performs:\n",
    "1. better than the baseline model\n",
    "2. comparably to the model with advice\n",
    "\n",
    "This pipeline differs from our other Master Pipeline file as this one uses an LDA model that's trained on both conversations (as before), but then applies the model separately to Conversation 1 and Conversation 2. Therefore, with 12 topics, we get 24 features in this file rather than the 12 in the other file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/samanthagarland/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from collections import Counter, defaultdict\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#gensim for topic modeling with LDA\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import NormModel\n",
    "\n",
    "#spacy for lemmatization\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "#xgboost for our classification model\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "#sklearn from cross-validation methods\n",
    "from sklearn.preprocessing import OneHotEncoder, scale, LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GridSearchCV, LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for pre-processing our transcripts\n",
    "\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stopWords] for doc in texts]\n",
    "\n",
    "def make_bigrams_combined(texts):\n",
    "    return [bigram_mod_combined[doc] for doc in texts]\n",
    "\n",
    "def make_bigrams_convo1(texts):\n",
    "    return [bigram_mod_convo1[doc] for doc in texts]\n",
    "\n",
    "def make_bigrams_convo2(texts):\n",
    "    return [bigram_mod_convo2[doc] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods for classification methods\n",
    "def predict_loo(clf, X_train, y_train, X_test, y_test):\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "    y_pred_tr = clf.predict(X_train)\n",
    "    y_pred_ts = clf.predict(X_test)\n",
    "    return y_pred_tr, y_pred_ts\n",
    "\n",
    "def compute_metrics(actual, pred):\n",
    "    accuracy = metrics.accuracy_score(actual, pred)\n",
    "    precision = metrics.precision_score(actual, pred)\n",
    "    recall = metrics.recall_score(actual, pred)\n",
    "    auc = metrics.roc_auc_score(actual, pred)\n",
    "    return accuracy, precision, recall, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "For an explanation of how we created this list, please see our Stop_Word_Rules file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 435 stop words.\n"
     ]
    }
   ],
   "source": [
    "stopWords = stopwords.words('english')\n",
    "stopWords = set([word.replace(\"'\", \"\") for word in stopWords])\n",
    "stopWords = stopWords.union(set([\"dr\", \"soo\", \"mmhmmm\", \"taiwan\", \"taiwanese\", \"communist\", \"mmmhmm\", \"'\", \"'cause\", \"'em\", 'a', 'aa', 'aaah', 'aah', 'ab', 'about', 'above', 'african', 'after', 'again', 'against', 'ah', 'ahh', 'ahhh', 'ahhhh', 'ahhm', 'ain', 'aint', 'alabama', 'alaska', 'all', 'alot', 'alright', 'alrighty', 'also', 'am', 'an', 'anand', 'and', 'andand', 'any', 'anyone', 'are', 'aren', 'arent', 'as', 'at', 'ay', 'b', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'bye', 'c', 'california', 'came', 'can', 'cant', 'clean', 'costa_rica', 'could', 'couldn', 'couldnt', 'cuz', 'd', 'de', 'did', 'didn', 'didnt', 'do', 'doc', 'does', 'doesn', 'doesnt', 'doin', 'doing', 'dokey', 'don', 'dont', 'down', 'during', 'e', 'each', 'eek', 'eh', 'em', 'er', 'et', 'etc', 'europe', 'f', 'few', 'florida','for', 'from', 'further', 'g', 'ga', 'gal', 'gee', 'geez', 'germany', 'get', 'go', 'goin', 'going', 'gonna', 'gosh', 'got', 'gotta', 'greek', 'gu', 'h', 'ha', 'had', 'hadn', 'hadnt', 'has', 'hasn', 'hasnt', 'have', 'haven', 'havent', 'having', 'he', 'hed', 'heh', 'hell', 'hello', 'henry', 'her', 'here', 'hers', 'herself', 'hes', 'hey', 'hi', 'him', 'himself', 'his', 'hm', 'hmm', 'hmmm', 'hodgkins', 'how', 'hows', 'huh', 'hum', 'i', 'id', 'if', 'ifif', 'ii', 'iii', 'ill', 'im', 'imrt', 'in', 'inaudible', 'indecipherable', 'indianapolis', 'into', 'is', 'isis', 'isn', 'isnt', 'it', 'itd', 'itit', 'itll', 'its', 'itself', 'ive', 'j', 'jeez', 'just', 'k', 'kay', 'kinda', 'l', 'laughs', 'le', 'leastno', 'legend', 'let', 'lets', 'like', 'll', 'look', 'lot', 'm', 'ma', 'maam', 'md', 'mdmd', 'me', 'mhm', 'mhmm', 'mhmmm', 'michigan', 'mightn', 'mightnt', 'mightve', 'mkay', 'mm', 'mmhm', 'mmhmm', 'mmkay', 'mmm', 'mmmhmm','mmmhmmm', 'mmmm', 'mmmmm', 'more', 'most', 'mustn', 'mustnt', 'mustve', 'my', 'myself', 'n', 'na', 'nah', 'nahuh', 'nd', 'ne', 'needn', 'neednt', 'nn', 'no', 'nooh', 'noooo', 'nope', 'nor', 'not', 'now', 'o', 'of', 'off', 'oh', 'ohh', 'ohhh', 'ohhhohohohoh', 'ohio', 'ok', 'okay', 'okey', 'on', 'once', 'only', 'oooh', 'or', 'oth', 'other', 'othumhmm', 'oughta', 'our', 'ours', 'ourselves', 'out', 'over', 'ow', 'own', 'p', 'patient', 'phi', 'physician', 'potter', 'pt', 'pt/so', 'q', 'r', 'rd', 're', 'right', 'ro', 's', 'said', 'same', 'say', 'see', 'shan', 'shant', 'she', 'shell', 'shes', 'should', 'shouldn', 'shouldnt', 'shouldve', 'so', 'some', 'sorta', 'sounds', 'st', 'stuff', 'such', 'swedish', 't', 'th', 'than', 'that', 'thatd', 'thatll', 'thats', 'thatsthat', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'thered', 'thereof', 'theres', 'thereve', 'these', 'thethe', 'thew', 'they', 'theyll', 'theyre', 'theyve', 'thing', 'things', 'this', 'those', 'through', 'ti', 'to', 'too', 'tthe', 'u', 'uh', 'uhh', 'uhhhhh', 'uhhm', 'uhhmm', 'uhhuh', 'uhm', 'uhmhmm', 'uhmhmmm', 'uhmmm', 'uhoh', 'uhum', 'um', 'umhmm', 'umhmmm', 'umm', 'ummm', 'ummmm', 'un', 'under', 'unhunh', 'until', 'up', 'us', 'uuh', 'v', 've', 'very', 'vietnam', 'virginia', 'w', 'walsh', 'wanna', 'was', 'washington', 'wasn', 'wasnt', 'we', 'wed', 'well', 'went', 'were', 'weren', 'werent', 'weve', 'wewe', 'what', 'whatd', 'whatev', 'whatever', 'whatnot', 'whats', 'when', 'where', 'wheres', 'whew', 'which', 'while', 'who', 'whoa', 'whom', 'whos', 'why', 'will', 'with', 'won', 'wont', 'would', 'wouldn', 'wouldnt', 'x', 'y', 'ya', 'yada', 'yah', 'yall', 'yea', 'yeah', 'yep', 'yepvery', 'yer', 'yeyeah', 'you', 'youd', 'youl', 'youll', 'your', 'youre', 'yours', 'yourself', 'yourselves', 'youve', 'youyou', 'yup', 'z']))\n",
    "print(\"We have\", len(stopWords), \"stop words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Our Models\n",
    "\n",
    "We use accuracy, precision, recall, and AUC as our performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline + Topics\n",
    "\n",
    "Variables:\n",
    "- age\n",
    "- gleason -- cancer grade\n",
    "- DVD -- control condition from previous study\n",
    "- tx2_binary -- preference (active surveillance vs treatment) before clinical appointment\n",
    "- combined_convos -- transcripts from all clinical appointments\n",
    "- as1 -- physician's advice for active surveillance\n",
    "- sur1 -- physician's advice for surgery\n",
    "- rad1 -- physician's advice for radiation therapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dvd_advice_text.csv') # 'dvd_withAdvice_final.csv'\n",
    "\n",
    "factors_all = [\"age\", \"gleason\", \"DVD\", \"tx2_binary\", \"combined_convos\", \"as1\", \"sur1\", \"rad1\"]\n",
    "df = df.dropna(subset=factors_all) #we only want to perform analysis on patients without any missing data for any of our variables\n",
    "df = df.reset_index(drop=True)\n",
    "factors_sub = [\"age\", \"gleason\", \"DVD\", \"tx2_binary\"] #these are the variables we'll actually use for this model\n",
    "\n",
    "lda_models = [] #keeps track of all lda models we produce\n",
    "\n",
    "X = df[factors_sub]\n",
    "y = df[\"txgot_binary\"]\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save indices of missing conversations to convert them into missing data before feeding into XGBoost model\n",
    "convo1_indices = []\n",
    "convo2_indices = []\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['Convo_1']):\n",
    "        convo1_indices.append(index)\n",
    "    if pd.isnull(row['Convo_2']):\n",
    "        convo2_indices.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convo 1 indices [2, 14, 25, 32, 61, 100, 122, 137]\n",
      "convo 2 indices [0, 1, 4, 6, 9, 13, 22, 24, 26, 28, 34, 35, 36, 37, 41, 45, 47, 50, 51, 54, 56, 57, 72, 73, 74, 75, 76, 77, 83, 84, 85, 87, 94, 95, 97, 99, 103, 106, 108, 110, 111, 112, 116, 117, 119, 121, 123, 126, 127, 128, 130]\n"
     ]
    }
   ],
   "source": [
    "print('convo 1 indices', convo1_indices)\n",
    "print('convo 2 indices', convo2_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Transcripts\n",
    "\n",
    "Note: As we will be applying the LDA model to conversations 1 and 2 separately, we need to process the texts in three ways: combined, only convo 1, and only convo2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect all conversations\n",
    "convo_combined = df[\"combined_convos\"]\n",
    "convo1 = df[\"Convo_1\"]\n",
    "convo2 = df[\"Convo_2\"]\n",
    "\n",
    "data_words_combined = list(sent_to_words(convo_combined))\n",
    "convo1 = list(sent_to_words(convo1))\n",
    "convo2 = list(sent_to_words(convo2))\n",
    "\n",
    "#creates bigrams of words commonly found together\n",
    "#for example, active_surveillance\n",
    "bigram_combined = gensim.models.Phrases(data_words_combined, min_count=2, threshold=100) \n",
    "bigram_convo1 = gensim.models.Phrases(convo1, min_count=2, threshold=100) \n",
    "bigram_convo2 = gensim.models.Phrases(convo2, min_count=2, threshold=100) \n",
    "\n",
    "bigram_mod_combined = gensim.models.phrases.Phraser(bigram_combined)\n",
    "bigram_mod_convo1 = gensim.models.phrases.Phraser(bigram_convo1)\n",
    "bigram_mod_convo2 = gensim.models.phrases.Phraser(bigram_convo2)\n",
    "\n",
    "#remove stop words\n",
    "data_words_nostops_combined = remove_stopwords(data_words_combined)\n",
    "data_words_nostops_convo1 = remove_stopwords(convo1)\n",
    "data_words_nostops_convo2 = remove_stopwords(convo2)\n",
    "\n",
    "data_words_bigrams_combined = make_bigrams_combined(data_words_nostops_combined)\n",
    "data_words_bigrams_convo1 = make_bigrams_convo1(data_words_nostops_convo1)\n",
    "data_words_bigrams_convo2 = make_bigrams_convo2(data_words_nostops_convo2)\n",
    "\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "#lemmatize the words\n",
    "data_lemmatized_combined = lemmatization(data_words_bigrams_combined, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "data_lemmatized_convo1 = lemmatization(data_words_bigrams_convo1, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "data_lemmatized_convo2 = lemmatization(data_words_bigrams_convo2, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "#remove stop words again (as lemmatization sometimes reduces words that turn out to be stop words)\n",
    "data_lemmatized_combined = [[word for word in convo if word not in stopWords] for convo in data_lemmatized_combined]\n",
    "data_lemmatized_convo1 = [[word for word in convo if word not in stopWords] for convo in data_lemmatized_convo1]\n",
    "data_lemmatized_convo2 = [[word for word in convo if word not in stopWords] for convo in data_lemmatized_convo2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOCV Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished round  139\n"
     ]
    }
   ],
   "source": [
    "#stores the testing predictions and training performance metrics\n",
    "predictions_ts = []\n",
    "accuracy_tr = []\n",
    "precision_tr = []\n",
    "recall_tr = []\n",
    "auc_tr = []\n",
    "\n",
    "# PARAMETERS\n",
    "# gradient-boosting\n",
    "max_depth = 3\n",
    "subsample = 0.9\n",
    "\n",
    "# LDA\n",
    "no_below = 0.0 # filters out words that are in fewer than no_below documents\n",
    "no_above = 0.7 # filters out words that are in more than no_above documents\n",
    "keep_n = 5000 # dictionary size\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "index = 1 # for keeping track of progress\n",
    "\n",
    "for train_index, test_index in loo.split(X): # Loop over all split possibilities\n",
    "    # first split up the dataset\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # convert into numpy arrays \n",
    "    combined_lemmatized = np.array(data_lemmatized_combined)\n",
    "    convo1_lemmatized = np.array(data_lemmatized_convo1)\n",
    "    convo2_lemmatized = np.array(data_lemmatized_convo2)\n",
    "    \n",
    "    # construct Dictionary from combined datasets \n",
    "    id2word_combined = corpora.Dictionary(combined_lemmatized[train_index]) # build corpus on training data only (NO LEAKAGE)\n",
    "    id2word_combined.filter_extremes(no_below = no_below, no_above = no_above, keep_n = keep_n, keep_tokens = None)\n",
    "\n",
    "    # create Bag of words model\n",
    "    corp_combined = [id2word_combined.doc2bow(text) for text in combined_lemmatized]\n",
    "    corp_convo1 = [id2word_combined.doc2bow(text) for text in convo1_lemmatized]\n",
    "    corp_convo2 = [id2word_combined.doc2bow(text) for text in convo2_lemmatized]\n",
    "    \n",
    "    corp_combined = np.array(corp_combined)\n",
    "    corp_convo1 = np.array(corp_convo1)\n",
    "    corp_convo2 = np.array(corp_convo2)\n",
    " \n",
    "    # split corpus by training and testing indices \n",
    "    corp_combined_train = corp_combined[train_index]\n",
    "    corp_convo1_train = corp_convo1[train_index]\n",
    "    corp_convo2_train = corp_convo2[train_index]\n",
    "    \n",
    "    corp_convo1_test = corp_convo1[test_index]\n",
    "    corp_convo2_test = corp_convo2[test_index]\n",
    "\n",
    "    # create LDA Model on combined dataset (on training data only)\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corp_combined_train,\n",
    "                                           id2word=id2word_combined,\n",
    "                                           num_topics=12, \n",
    "                                           random_state=100,\n",
    "                                           update_every=3,\n",
    "                                           chunksize=20,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "    \n",
    "    # convert back into dataframe so we can append topic distributions\n",
    "    X_train = pd.DataFrame({'age':X_train[:,0],'gleason':X_train[:,1], \"DVD\": X_train[:,2], \"tx2_binary\": X_train[:, 3]})\n",
    "    X_test = pd.DataFrame({'age':X_test[:,0],'gleason':X_test[:,1],\"DVD\": X_test[:,2], \"tx2_binary\": X_test[:, 3]})\n",
    "\n",
    "    # get topic distributions for convo_1 and convo_2 training\n",
    "    distributions_convo1 = lda_model[corp_convo1_train] # training\n",
    "    distributions_convo2 = lda_model[corp_convo2_train]\n",
    "    length = len(corp_convo1_train) \n",
    "    \n",
    "    topic_dist = [] # topic distributions for convo_1 training\n",
    "    for i in range(12): # number of topics in topic model\n",
    "        topic_dist.append([0.0]*length) # initialize all topic distributions to 0\n",
    "    for en, row in enumerate(distributions_convo1):\n",
    "        topics = row[0]\n",
    "        for topic in topics: # list of tuples that contains non-zero topic distributions in format [(1,.034), (4, .458)...]\n",
    "            topic_dist[topic[0]][en] = topic[1]\n",
    "        if en in convo1_indices: # if there is no conversation, treat as missing data\n",
    "            for i in range(12):\n",
    "                topic_dist[i][en] = np.nan\n",
    "    for i in range(12): # store topic distributions for convo 1 in training dataframe\n",
    "        X_train['c1_topic' + str(i)] = topic_dist[i]\n",
    "        \n",
    "    topic_dist = [] # topic distributions for convo_2 training\n",
    "    for i in range(12):\n",
    "        topic_dist.append([0.0]*length)\n",
    "    for en, row in enumerate(distributions_convo2):\n",
    "        topics = row[0]\n",
    "        for topic in topics:\n",
    "            topic_dist[topic[0]][en] = topic[1]\n",
    "        if en in convo2_indices:\n",
    "            for i in range(12):\n",
    "                topic_dist[i][en] = np.nan\n",
    "    for i in range(12):\n",
    "        X_train['c2_topic' + str(i)] = topic_dist[i]\n",
    " \n",
    "    # get topic distributions for convo_1 and convo_2 testing\n",
    "    distributions_convo1 = lda_model[corp_convo1_test] # testing\n",
    "    distributions_convo2 = lda_model[corp_convo2_test]\n",
    "    length = len(corp_convo1_test) \n",
    "    \n",
    "    topic_dist = [] # topic distributions for convo_1 testing\n",
    "    for i in range(12):\n",
    "        topic_dist.append([0.0]*length)\n",
    "    for en, row in enumerate(distributions_convo1):\n",
    "        topics = row[0]\n",
    "        for topic in topics:\n",
    "            topic_dist[topic[0]][en] = topic[1]\n",
    "        if en in convo1_indices:\n",
    "            for i in range(12):\n",
    "                topic_dist[i][en] = np.nan\n",
    "    for i in range(12):\n",
    "        X_test['c1_topic' + str(i)] = topic_dist[i]\n",
    "        \n",
    "    topic_dist = [] # topic distributions for convo_2 testing\n",
    "    for i in range(12):\n",
    "        topic_dist.append([0.0]*length)\n",
    "    for en, row in enumerate(distributions_convo2):\n",
    "        topics = row[0]\n",
    "        for topic in topics:\n",
    "            topic_dist[topic[0]][en] = topic[1]\n",
    "        if en in convo2_indices:\n",
    "            for i in range(12):\n",
    "                topic_dist[i][en] = np.nan\n",
    "    for i in range(12):\n",
    "        X_test['c2_topic' + str(i)] = topic_dist[i]\n",
    "   \n",
    "    # fit model and predict\n",
    "    xgb = XGBClassifier(max_depth = max_depth, subsample = subsample)\n",
    "    y_pred_tr, y_pred_ts = predict_loo(xgb, X_train, y_train, X_test, y_test)\n",
    "    predictions_ts.append(y_pred_ts) #save prediction from each run-through\n",
    "    \n",
    "    # compute and store training performance\n",
    "    acc, prec, rec, auc = compute_metrics(y_train, y_pred_tr)\n",
    "    accuracy_tr.append(acc)\n",
    "    precision_tr.append(prec)\n",
    "    recall_tr.append(rec)\n",
    "    auc_tr.append(auc)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('finished round ', index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.9947346470649566\n",
      "training precision:  0.9984663338847638\n",
      "training recall:  0.9799689660036677\n",
      "training auc:  0.9897433572211396\n",
      "\n",
      "testing accuracy:  0.7697841726618705\n",
      "testing precision:  0.5263157894736842\n",
      "testing recall:  0.5882352941176471\n",
      "testing auc  0.7084033613445379\n"
     ]
    }
   ],
   "source": [
    "# training performance\n",
    "print('training accuracy: ', np.average(accuracy_tr))\n",
    "print('training precision: ', np.average(precision_tr))\n",
    "print('training recall: ', np.average(recall_tr))\n",
    "print('training auc: ', np.average(auc_tr))\n",
    "\n",
    "print()\n",
    "\n",
    "# testing performance\n",
    "accuracy, precision, recall, auc = compute_metrics(y, predictions_ts)\n",
    "print('testing accuracy: ', accuracy)\n",
    "print('testing precision: ', precision)\n",
    "print('testing recall: ', recall)\n",
    "print('testing auc ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "Variables:\n",
    "- age\n",
    "- gleason -- cancer grade\n",
    "- DVD -- control condition from previous study\n",
    "- tx2_binary -- preference (active surveillance vs treatment) before clinical appointment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished round  139\n"
     ]
    }
   ],
   "source": [
    "#stores the testing predictions and training performance metrics\n",
    "predictions_ts = []\n",
    "accuracy_tr = []\n",
    "precision_tr = []\n",
    "recall_tr = []\n",
    "auc_tr = []\n",
    "\n",
    "# Define parameters for gradient-boosting algorithm\n",
    "max_depth = 3\n",
    "subsample = 0.9\n",
    "\n",
    "X = df[[\"age\", \"gleason\", \"DVD\", \"tx2_binary\"]]\n",
    "y = df[\"txgot_binary\"]\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "index = 1 # for keeping track of progress\n",
    "\n",
    "for train_index, test_index in loo.split(X): # Loop over all split possibilities\n",
    "    #first split up the dataset\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # fit model and predict\n",
    "    xgb = XGBClassifier(max_depth = max_depth, subsample = subsample)\n",
    "    y_pred_tr, y_pred_ts = predict_loo(xgb, X_train, y_train, X_test, y_test)\n",
    "    predictions_ts.append(y_pred_ts)\n",
    "    \n",
    "    # compute and store training performance\n",
    "    acc, prec, rec, auc = compute_metrics(y_train, y_pred_tr)\n",
    "    accuracy_tr.append(acc)\n",
    "    precision_tr.append(prec)\n",
    "    recall_tr.append(rec)\n",
    "    auc_tr.append(auc)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('finished round ', index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.8702950682931916\n",
      "training precision:  0.8404059000117805\n",
      "training recall:  0.5803229074494415\n",
      "training auc:  0.7722509469652932\n",
      "\n",
      "testing accuracy:  0.7553956834532374\n",
      "testing precision:  0.5\n",
      "testing recall:  0.38235294117647056\n",
      "testing auc  0.6292717086834734\n"
     ]
    }
   ],
   "source": [
    "# training performance\n",
    "print('training accuracy: ', np.average(accuracy_tr))\n",
    "print('training precision: ', np.average(precision_tr))\n",
    "print('training recall: ', np.average(recall_tr))\n",
    "print('training auc: ', np.average(auc_tr))\n",
    "\n",
    "print()\n",
    "\n",
    "# testing performance\n",
    "accuracy, precision, recall, auc = compute_metrics(y, predictions_ts)\n",
    "print('testing accuracy: ', accuracy)\n",
    "print('testing precision: ', precision)\n",
    "print('testing recall: ', recall)\n",
    "print('testing auc ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline and Advice\n",
    "\n",
    "Variables:\n",
    "- age\n",
    "- gleason -- cancer grade\n",
    "- DVD -- control condition from previous study\n",
    "- tx2_binary -- preference (active surveillance vs treatment) before clinical appointment\n",
    "- as1 -- physician's advice for active surveillance\n",
    "- sur1 -- physician's advice for surgery\n",
    "- rad1 -- physician's advice for radiation therapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished round  139\n"
     ]
    }
   ],
   "source": [
    "#stores the testing predictions and training performance metrics\n",
    "predictions_ts = []\n",
    "accuracy_tr = []\n",
    "precision_tr = []\n",
    "recall_tr = []\n",
    "auc_tr = []\n",
    "\n",
    "# Define parameters for xgboost\n",
    "max_depth = 3\n",
    "subsample = 0.9\n",
    "\n",
    "X = df[[\"age\", \"gleason\", \"DVD\", \"tx2_binary\", \"as1\", \"sur1\", \"rad1\"]]\n",
    "y = df[\"txgot_binary\"]\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "index = 1 # for keeping track of progress\n",
    "\n",
    "for train_index, test_index in loo.split(X): # Loop over all split possibilities\n",
    "    #first split up the dataset\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # fit model and predict\n",
    "    xgb = XGBClassifier(max_depth = max_depth, subsample = subsample)\n",
    "    y_pred_tr, y_pred_ts = predict_loo(xgb, X_train, y_train, X_test, y_test)\n",
    "    predictions_ts.append(y_pred_ts)\n",
    "    \n",
    "    # compute and store training performance\n",
    "    acc, prec, rec, auc = compute_metrics(y_train, y_pred_tr)\n",
    "    accuracy_tr.append(acc)\n",
    "    precision_tr.append(prec)\n",
    "    recall_tr.append(rec)\n",
    "    auc_tr.append(auc)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('finished round ', index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.9393181107288082\n",
      "training precision:  0.8825104214664199\n",
      "training recall:  0.8680413957603971\n",
      "training auc:  0.9152109105452314\n",
      "\n",
      "testing accuracy:  0.7769784172661871\n",
      "testing precision:  0.5517241379310345\n",
      "testing recall:  0.47058823529411764\n",
      "testing auc  0.673389355742297\n"
     ]
    }
   ],
   "source": [
    "# training performance\n",
    "print('training accuracy: ', np.average(accuracy_tr))\n",
    "print('training precision: ', np.average(precision_tr))\n",
    "print('training recall: ', np.average(recall_tr))\n",
    "print('training auc: ', np.average(auc_tr))\n",
    "\n",
    "print()\n",
    "\n",
    "# testing performance\n",
    "accuracy, precision, recall, auc = compute_metrics(y, predictions_ts)\n",
    "print('testing accuracy: ', accuracy)\n",
    "print('testing precision: ', precision)\n",
    "print('testing recall: ', recall)\n",
    "print('testing auc ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Feature Importances\n",
    "\n",
    "After using the metrics from above to determine that the parameters we set lead to good accuracy and AUC, we run this on the entire corpus of transcripts to create our master model. From this model, we calculate the feature importances of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dvd_withAdvice_final.csv')\n",
    "\n",
    "factors_all = [\"age\", \"gleason\", \"DVD\", \"tx2_binary\", \"combined_convos\", \"as1\", \"sur1\", \"rad1\"]\n",
    "df = df.dropna(subset=factors_all) # we only want to perform analysis on patients without any missing data for any of our variables\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "factors_sub = [\"age\", \"gleason\", \"DVD\", \"tx2_binary\"] #these are the variables we'll actually use for this model\n",
    "X = df[factors_sub]\n",
    "y = df[\"txgot_binary\"]\n",
    "\n",
    "# save indices of missing conversations to convert them into missing data before feeding into XGBoost model\n",
    "convo1_indices = []\n",
    "convo2_indices = []\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['Convo_1']):\n",
    "        convo1_indices.append(index)\n",
    "    if pd.isnull(row['Convo_2']):\n",
    "        convo2_indices.append(index)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "#collect all conversations\n",
    "convo_combined = df[\"combined_convos\"]\n",
    "convo1 = df[\"Convo_1\"]\n",
    "convo2 = df[\"Convo_2\"]\n",
    "\n",
    "data_words_combined = list(sent_to_words(convo_combined))\n",
    "convo1 = list(sent_to_words(convo1))\n",
    "convo2 = list(sent_to_words(convo2))\n",
    "\n",
    "#creates bigrams of words commonly found together\n",
    "#for example, active_surveillance\n",
    "bigram_combined = gensim.models.Phrases(data_words_combined, min_count=2, threshold=100) \n",
    "bigram_convo1 = gensim.models.Phrases(convo1, min_count=2, threshold=100) \n",
    "bigram_convo2 = gensim.models.Phrases(convo2, min_count=2, threshold=100) \n",
    "\n",
    "bigram_mod_combined = gensim.models.phrases.Phraser(bigram_combined)\n",
    "bigram_mod_convo1 = gensim.models.phrases.Phraser(bigram_convo1)\n",
    "bigram_mod_convo2 = gensim.models.phrases.Phraser(bigram_convo2)\n",
    "\n",
    "#remove stop words\n",
    "data_words_nostops_combined = remove_stopwords(data_words_combined)\n",
    "data_words_nostops_convo1 = remove_stopwords(convo1)\n",
    "data_words_nostops_convo2 = remove_stopwords(convo2)\n",
    "\n",
    "data_words_bigrams_combined = make_bigrams_combined(data_words_nostops_combined)\n",
    "data_words_bigrams_convo1 = make_bigrams_convo1(data_words_nostops_convo1)\n",
    "data_words_bigrams_convo2 = make_bigrams_convo2(data_words_nostops_convo2)\n",
    "\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "#lemmatize the words\n",
    "data_lemmatized_combined = lemmatization(data_words_bigrams_combined, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "data_lemmatized_convo1 = lemmatization(data_words_bigrams_convo1, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "data_lemmatized_convo2 = lemmatization(data_words_bigrams_convo2, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "#remove stop words again (as lemmatization sometimes reduces words that turn out to be stop words)\n",
    "data_lemmatized_combined = [[word for word in convo if word not in stopWords] for convo in data_lemmatized_combined]\n",
    "data_lemmatized_convo1 = [[word for word in convo if word not in stopWords] for convo in data_lemmatized_convo1]\n",
    "data_lemmatized_convo2 = [[word for word in convo if word not in stopWords] for convo in data_lemmatized_convo2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "\n",
    "#xgboost\n",
    "max_depth = 3\n",
    "subsample = 0.9\n",
    "\n",
    "#LDA\n",
    "no_below = 0.1\n",
    "no_above = 0.7\n",
    "keep_n = 5000\n",
    "\n",
    "# construct Dictionary from combined datasets \n",
    "id2word_combined = corpora.Dictionary(combined_lemmatized) # build corpus on training data only (NO LEAKAGE)\n",
    "id2word_combined.filter_extremes(no_below = no_below, no_above = no_above, keep_n = keep_n, keep_tokens = None)\n",
    "\n",
    "# create Bag of words model\n",
    "corp_combined = [id2word_combined.doc2bow(text) for text in combined_lemmatized]\n",
    "corp_combined = np.array(corp_combined)\n",
    "corp_convo1 = [id2word_combined.doc2bow(text) for text in convo1_lemmatized]\n",
    "corp_convo1 = np.array(corp_convo1)\n",
    "corp_convo2 = [id2word_combined.doc2bow(text) for text in convo2_lemmatized]\n",
    "corp_convo2 = np.array(corp_convo2)\n",
    "\n",
    "# Create LDA Model with combined corpus from above\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corp_combined,\n",
    "                                       id2word=id2word_combined,\n",
    "                                       num_topics=12, \n",
    "                                       random_state=100,\n",
    "                                       update_every=3,\n",
    "                                       chunksize=20,\n",
    "                                       passes=10,\n",
    "                                       alpha='auto',\n",
    "                                       per_word_topics=True)\n",
    "\n",
    "# revert X back to dataframe so we can add on the topic distributions\n",
    "X = pd.DataFrame({'age':X[:,0],'gleason':X[:,1], \"DVD\": X[:,2], \"tx2_binary\": X[:, 3]})\n",
    "\n",
    "# get topic distributions for convo_1 and convo_2 \n",
    "distributions_convo1 = lda_model[corp_convo1] # \n",
    "distributions_convo2 = lda_model[corp_convo2]\n",
    "length = len(corp_convo1) \n",
    "    \n",
    "topic_dist = [] # topic distributions for convo_1 training\n",
    "for i in range(12): # number of topics in topic model\n",
    "    topic_dist.append([0.0]*length)\n",
    "for en, row in enumerate(distributions_convo1):\n",
    "    topics = row[0]\n",
    "    for topic in topics: # list of tuples that contains non-zero topic distributions in format [(1,.034), (4, .458)...]\n",
    "        topic_dist[topic[0]][en] = topic[1]\n",
    "    if en in convo1_indices:\n",
    "        for i in range(12):\n",
    "            topic_dist[i][en] = np.nan\n",
    "for i in range(12):\n",
    "    X['c1_topic' + str(i)] = topic_dist[i]\n",
    "\n",
    "topic_dist = [] # topic distributions for convo_2 training\n",
    "for i in range(12):\n",
    "    topic_dist.append([0.0]*length)\n",
    "for en, row in enumerate(distributions_convo2):\n",
    "    topics = row[0]\n",
    "    for topic in topics:\n",
    "        topic_dist[topic[0]][en] = topic[1]\n",
    "    if en in convo2_indices:\n",
    "        for i in range(12):\n",
    "            topic_dist[i][en] = np.nan\n",
    "for i in range(12):\n",
    "    X['c2_topic' + str(i)] = topic_dist[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a24ca5b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c1_topic7', 0.16829745]\n",
      "['c2_topic7', 0.13111547]\n",
      "['c1_topic1', 0.113502935]\n",
      "['age', 0.10763209]\n",
      "['c1_topic0', 0.10763209]\n",
      "['c1_topic11', 0.10176125]\n",
      "['gleason', 0.0665362]\n",
      "['c2_topic0', 0.056751467]\n",
      "['c2_topic4', 0.04892368]\n",
      "['tx2_binary', 0.045009784]\n",
      "['c2_topic1', 0.023483366]\n",
      "['c1_topic4', 0.01369863]\n",
      "['c2_topic11', 0.009784736]\n",
      "['DVD', 0.0058708414]\n",
      "['c2_topic10', 0.0]\n",
      "['c1_topic8', 0.0]\n",
      "['c1_topic10', 0.0]\n",
      "['c1_topic6', 0.0]\n",
      "['c1_topic5', 0.0]\n",
      "['c2_topic2', 0.0]\n",
      "['c1_topic3', 0.0]\n",
      "['c1_topic2', 0.0]\n",
      "['c2_topic3', 0.0]\n",
      "['c2_topic5', 0.0]\n",
      "['c2_topic6', 0.0]\n",
      "['c2_topic8', 0.0]\n",
      "['c2_topic9', 0.0]\n",
      "['c1_topic9', 0.0]\n"
     ]
    }
   ],
   "source": [
    "#create our model\n",
    "clf = XGBClassifier(max_depth = max_depth, subsample = subsample)\n",
    "X_np = np.array(X)\n",
    "clf.fit(X_np, y)\n",
    "\n",
    "#plots the feature importances\n",
    "temp = plot_importance(clf)\n",
    "pyplot.show(temp)\n",
    "\n",
    "#lists the features in order of importance\n",
    "sorted_idx = np.argsort(clf.feature_importances_)[::-1]\n",
    "for index in sorted_idx:\n",
    "    print([X.columns[index], clf.feature_importances_[index]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ['c1_topic11', 0.19094488], ['age', 0.16929133], ['c2_topic7', 0.15551181], ['c1_topic7', 0.12992126], ['c1_topic0', 0.10236221], ['gleason', 0.07874016], ['c2_topic11', 0.061023623], ['tx2_binary', 0.05511811], ['c2_topic0', 0.037401576], ['DVD', 0.00984252], ['c1_topic1', 0.007874016], ['c2_topic1', 0.001968504]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVD Topics:\n",
      "[(0,\n",
      "  '0.009*\"robotic\" + 0.008*\"erectile\" + 0.005*\"book\" + 0.005*\"situation\" + '\n",
      "  '0.005*\"robot\" + 0.004*\"lymph_node\" + 0.004*\"sphincter\" + 0.004*\"pad\" + '\n",
      "  '0.004*\"physical\" + 0.003*\"generally\" + 0.003*\"volume\" + 0.003*\"additional\" '\n",
      "  '+ 0.003*\"outside\" + 0.003*\"rare\" + 0.003*\"spare\" + 0.003*\"damage\" + '\n",
      "  '0.003*\"tumor\" + 0.003*\"activity\" + 0.003*\"bowel\" + 0.003*\"rate\" + '\n",
      "  '0.003*\"heal\" + 0.003*\"pathologist\" + 0.003*\"pathology\" + 0.003*\"research\" + '\n",
      "  '0.003*\"anywhere\" + 0.003*\"fix\" + 0.003*\"dry\" + 0.003*\"level\" + 0.003*\"add\" '\n",
      "  '+ 0.003*\"wear\" + 0.003*\"recover\" + 0.003*\"middle\" + 0.003*\"penis\" + '\n",
      "  '0.003*\"kill\" + 0.003*\"health\" + 0.002*\"viagra\" + 0.002*\"stage\" + '\n",
      "  '0.002*\"write\" + 0.002*\"learn\" + 0.002*\"scar\" + 0.002*\"notice\" + 0.002*\"top\" '\n",
      "  '+ 0.002*\"soon\" + 0.002*\"freeze\" + 0.002*\"definitely\" + 0.002*\"nurse\" + '\n",
      "  '0.002*\"ability\" + 0.002*\"active\" + 0.002*\"bathroom\" + 0.002*\"blood_flow\"'),\n",
      " (1,\n",
      "  '0.005*\"dad\" + 0.004*\"listen\" + 0.004*\"hormone\" + 0.004*\"brother\" + '\n",
      "  '0.004*\"pee\" + 0.003*\"heal\" + 0.003*\"walk\" + 0.003*\"morning\" + '\n",
      "  '0.003*\"blood_pressure\" + 0.003*\"pull\" + 0.003*\"bump\" + 0.003*\"pill\" + '\n",
      "  '0.003*\"book\" + 0.003*\"family\" + 0.003*\"explain\" + 0.003*\"job\" + '\n",
      "  '0.003*\"belly\" + 0.003*\"spare\" + 0.003*\"range\" + 0.003*\"situation\" + '\n",
      "  '0.003*\"outside\" + 0.003*\"lymph_node\" + 0.003*\"drink\" + 0.002*\"recover\" + '\n",
      "  '0.002*\"fly\" + 0.002*\"smoke\" + 0.002*\"medical\" + 0.002*\"notice\" + '\n",
      "  '0.002*\"leg\" + 0.002*\"benefit\" + 0.002*\"list\" + 0.002*\"external\" + '\n",
      "  '0.002*\"lay\" + 0.002*\"outcome\" + 0.002*\"small_incision\" + 0.002*\"mom\" + '\n",
      "  '0.002*\"operation\" + 0.002*\"sexual\" + 0.002*\"past\" + 0.002*\"mention\" + '\n",
      "  '0.002*\"burn\" + 0.002*\"appreciate\" + 0.002*\"robot\" + 0.002*\"skin\" + '\n",
      "  '0.002*\"dry\" + 0.002*\"rate\" + 0.002*\"wife\" + 0.002*\"bowel_movement\" + '\n",
      "  '0.002*\"folk\" + 0.002*\"definitely\"'),\n",
      " (2,\n",
      "  '0.000*\"implant\" + 0.000*\"external_beam\" + 0.000*\"bowel\" + 0.000*\"group\" + '\n",
      "  '0.000*\"likelihood\" + 0.000*\"brachytherapy\" + 0.000*\"beam\" + '\n",
      "  '0.000*\"lymph_node\" + 0.000*\"testosterone\" + 0.000*\"instance\" + '\n",
      "  '0.000*\"benefit\" + 0.000*\"hormone_therapy\" + 0.000*\"proton\" + 0.000*\"datum\" '\n",
      "  '+ 0.000*\"surgical\" + 0.000*\"tumor\" + 0.000*\"urologist\" + 0.000*\"hormone\" + '\n",
      "  '0.000*\"true\" + 0.000*\"choose\" + 0.000*\"outside\" + 0.000*\"approach\" + '\n",
      "  '0.000*\"deliver\" + 0.000*\"amount\" + 0.000*\"recover\" + 0.000*\"choice\" + '\n",
      "  '0.000*\"erectile\" + 0.000*\"sexual\" + 0.000*\"listen\" + 0.000*\"alone\" + '\n",
      "  '0.000*\"outcome\" + 0.000*\"urinate\" + 0.000*\"needle\" + 0.000*\"recurrence\" + '\n",
      "  '0.000*\"line\" + 0.000*\"volume\" + 0.000*\"rectal_exam\" + 0.000*\"robotic\" + '\n",
      "  '0.000*\"certain\" + 0.000*\"xray\" + 0.000*\"longterm\" + 0.000*\"drive\" + '\n",
      "  '0.000*\"job\" + 0.000*\"compare\" + 0.000*\"essentially\" + 0.000*\"spare\" + '\n",
      "  '0.000*\"road\" + 0.000*\"generally\" + 0.000*\"middle\" + 0.000*\"anymore\"'),\n",
      " (3,\n",
      "  '0.000*\"bowel\" + 0.000*\"implant\" + 0.000*\"group\" + 0.000*\"external_beam\" + '\n",
      "  '0.000*\"lymph_node\" + 0.000*\"beam\" + 0.000*\"benefit\" + 0.000*\"rate\" + '\n",
      "  '0.000*\"testosterone\" + 0.000*\"likelihood\" + 0.000*\"erectile\" + '\n",
      "  '0.000*\"situation\" + 0.000*\"surgical\" + 0.000*\"certain\" + 0.000*\"external\" + '\n",
      "  '0.000*\"brachytherapy\" + 0.000*\"tumor\" + 0.000*\"needle\" + 0.000*\"sexual\" + '\n",
      "  '0.000*\"drive\" + 0.000*\"middle\" + 0.000*\"grade\" + 0.000*\"true\" + '\n",
      "  '0.000*\"outside\" + 0.000*\"urologist\" + 0.000*\"deliver\" + 0.000*\"muscle\" + '\n",
      "  '0.000*\"notice\" + 0.000*\"approach\" + 0.000*\"choose\" + 0.000*\"recurrence\" + '\n",
      "  '0.000*\"fill\" + 0.000*\"instance\" + 0.000*\"rectal\" + 0.000*\"hormone\" + '\n",
      "  '0.000*\"size\" + 0.000*\"proton\" + 0.000*\"recover\" + 0.000*\"tube\" + '\n",
      "  '0.000*\"hormonal_therapy\" + 0.000*\"listen\" + 0.000*\"thought\" + '\n",
      "  '0.000*\"lowrisk\" + 0.000*\"add\" + 0.000*\"operation\" + 0.000*\"compare\" + '\n",
      "  '0.000*\"volume\" + 0.000*\"radiate\" + 0.000*\"sleep\" + 0.000*\"road\"'),\n",
      " (4,\n",
      "  '0.020*\"hormone_therapy\" + 0.013*\"trial\" + 0.011*\"hormone\" + '\n",
      "  '0.009*\"testosterone\" + 0.006*\"walk\" + 0.006*\"tube\" + 0.005*\"proton\" + '\n",
      "  '0.005*\"randomize\" + 0.004*\"benefit\" + 0.004*\"bowel\" + '\n",
      "  '0.004*\"bowel_movement\" + 0.004*\"heart_attack\" + 0.004*\"sexual\" + '\n",
      "  '0.004*\"email\" + 0.004*\"ct_scan\" + 0.004*\"implant\" + 0.004*\"beam\" + '\n",
      "  '0.004*\"add\" + 0.004*\"head\" + 0.004*\"melanoma\" + 0.003*\"enroll\" + '\n",
      "  '0.003*\"middle\" + 0.003*\"grade\" + 0.003*\"sign\" + 0.003*\"forth\" + '\n",
      "  '0.003*\"mention\" + 0.003*\"equal\" + 0.003*\"name\" + 0.003*\"bypass\" + '\n",
      "  '0.003*\"clinic\" + 0.003*\"hop\" + 0.003*\"position\" + 0.003*\"phone\" + '\n",
      "  '0.003*\"finasteride\" + 0.003*\"nodule\" + 0.003*\"rest\" + 0.003*\"hair\" + '\n",
      "  '0.003*\"pick\" + 0.003*\"north\" + 0.003*\"job\" + 0.003*\"water\" + 0.003*\"line\" + '\n",
      "  '0.003*\"develop\" + 0.003*\"dysfunction\" + 0.003*\"category\" + 0.003*\"research\" '\n",
      "  '+ 0.003*\"lean\" + 0.003*\"road\" + 0.003*\"odd\" + 0.003*\"kill\"'),\n",
      " (5,\n",
      "  '0.000*\"external_beam\" + 0.000*\"group\" + 0.000*\"bowel\" + 0.000*\"implant\" + '\n",
      "  '0.000*\"hormone_therapy\" + 0.000*\"likelihood\" + 0.000*\"beam\" + '\n",
      "  '0.000*\"benefit\" + 0.000*\"instance\" + 0.000*\"deliver\" + 0.000*\"sleep\" + '\n",
      "  '0.000*\"datum\" + 0.000*\"notice\" + 0.000*\"urologist\" + 0.000*\"radiate\" + '\n",
      "  '0.000*\"situation\" + 0.000*\"testosterone\" + 0.000*\"brachytherapy\" + '\n",
      "  '0.000*\"tumor\" + 0.000*\"size\" + 0.000*\"erectile\" + 0.000*\"needle\" + '\n",
      "  '0.000*\"level\" + 0.000*\"recover\" + 0.000*\"range\" + 0.000*\"job\" + '\n",
      "  '0.000*\"longterm\" + 0.000*\"approach\" + 0.000*\"potentially\" + '\n",
      "  '0.000*\"possible\" + 0.000*\"rid\" + 0.000*\"damage\" + 0.000*\"add\" + '\n",
      "  '0.000*\"amount\" + 0.000*\"true\" + 0.000*\"mention\" + 0.000*\"hormone\" + '\n",
      "  '0.000*\"surgical\" + 0.000*\"suggest\" + 0.000*\"system\" + 0.000*\"begin\" + '\n",
      "  '0.000*\"robotic\" + 0.000*\"figure\" + 0.000*\"surveillance\" + 0.000*\"record\" + '\n",
      "  '0.000*\"rectal\" + 0.000*\"urinate\" + 0.000*\"drive\" + 0.000*\"outcome\" + '\n",
      "  '0.000*\"short\"'),\n",
      " (6,\n",
      "  '0.000*\"win\" + 0.000*\"cyberknife\" + 0.000*\"definitive_management\" + '\n",
      "  '0.000*\"propensity\" + 0.000*\"fixable\" + 0.000*\"mainstay\" + 0.000*\"statistic\" '\n",
      "  '+ 0.000*\"refresh\" + 0.000*\"external_beam\" + 0.000*\"report\" + '\n",
      "  '0.000*\"sensitive\" + 0.000*\"accelerator\" + 0.000*\"money\" + 0.000*\"client\" + '\n",
      "  '0.000*\"histology\" + 0.000*\"scan\" + 0.000*\"tease\" + 0.000*\"group\" + '\n",
      "  '0.000*\"correlation\" + 0.000*\"detect\" + 0.000*\"implant\" + 0.000*\"bowel\" + '\n",
      "  '0.000*\"testosterone\" + 0.000*\"tumor\" + 0.000*\"horseback_rid\" + '\n",
      "  '0.000*\"needle\" + 0.000*\"stage\" + 0.000*\"instance\" + 0.000*\"brachytherapy\" + '\n",
      "  '0.000*\"amount\" + 0.000*\"benefit\" + 0.000*\"quadrant\" + 0.000*\"choose\" + '\n",
      "  '0.000*\"likelihood\" + 0.000*\"outcome\" + 0.000*\"opinion\" + '\n",
      "  '0.000*\"necessarily\" + 0.000*\"compare\" + 0.000*\"datum\" + 0.000*\"longterm\" + '\n",
      "  '0.000*\"possible\" + 0.000*\"thought\" + 0.000*\"paper\" + 0.000*\"lymph\" + '\n",
      "  '0.000*\"deliver\" + 0.000*\"borrow\" + 0.000*\"medical\" + 0.000*\"wife\" + '\n",
      "  '0.000*\"radiate\" + 0.000*\"volume\"'),\n",
      " (7,\n",
      "  '0.008*\"external_beam\" + 0.006*\"implant\" + 0.005*\"brachytherapy\" + '\n",
      "  '0.005*\"group\" + 0.005*\"bowel\" + 0.004*\"beam\" + 0.004*\"needle\" + '\n",
      "  '0.003*\"external\" + 0.003*\"deliver\" + 0.003*\"irritation\" + 0.003*\"longterm\" '\n",
      "  '+ 0.003*\"clinical_trial\" + 0.003*\"amount\" + 0.003*\"datum\" + '\n",
      "  '0.003*\"possible\" + 0.003*\"essentially\" + 0.003*\"rectal\" + 0.003*\"ct_scan\" + '\n",
      "  '0.003*\"beacon\" + 0.003*\"outcome\" + 0.002*\"urinate\" + 0.002*\"radiate\" + '\n",
      "  '0.002*\"interested\" + 0.002*\"tumor\" + 0.002*\"fill\" + 0.002*\"instance\" + '\n",
      "  '0.002*\"choose\" + 0.002*\"urologist\" + 0.002*\"testosterone\" + 0.002*\"hormone\" '\n",
      "  '+ 0.002*\"benefit\" + 0.002*\"size\" + 0.002*\"lowrisk\" + 0.002*\"drug\" + '\n",
      "  '0.002*\"generally\" + 0.002*\"certain\" + 0.002*\"compare\" + 0.002*\"marker\" + '\n",
      "  '0.002*\"continue\" + 0.002*\"likelihood\" + 0.002*\"email\" + 0.002*\"machine\" + '\n",
      "  '0.002*\"completely\" + 0.002*\"increase\" + 0.002*\"line\" + 0.002*\"grade\" + '\n",
      "  '0.002*\"medical\" + 0.002*\"department\" + 0.002*\"ultrasound\" + '\n",
      "  '0.002*\"rectal_exam\"'),\n",
      " (8,\n",
      "  '0.000*\"group\" + 0.000*\"react\" + 0.000*\"wife\" + 0.000*\"brother\" + '\n",
      "  '0.000*\"leg\" + 0.000*\"bug\" + 0.000*\"needle\" + 0.000*\"saturation\" + '\n",
      "  '0.000*\"grandkid\" + 0.000*\"bathroom\" + 0.000*\"irritation\" + 0.000*\"diagnose\" '\n",
      "  '+ 0.000*\"dad\" + 0.000*\"morning\" + 0.000*\"shake\" + 0.000*\"family\" + '\n",
      "  '0.000*\"surveillance\" + 0.000*\"suggest\" + 0.000*\"sociology\" + '\n",
      "  '0.000*\"external_beam\" + 0.000*\"lump\" + 0.000*\"christma\" + 0.000*\"tumor\" + '\n",
      "  '0.000*\"frank\" + 0.000*\"record\" + 0.000*\"bowel\" + 0.000*\"kid\" + 0.000*\"miss\" '\n",
      "  '+ 0.000*\"template\" + 0.000*\"operation\" + 0.000*\"blood_pressure\" + '\n",
      "  '0.000*\"benefit\" + 0.000*\"unlikely\" + 0.000*\"stick\" + 0.000*\"instance\" + '\n",
      "  '0.000*\"likelihood\" + 0.000*\"approach\" + 0.000*\"diarrhea\" + '\n",
      "  '0.000*\"rectal_exam\" + 0.000*\"quit\" + 0.000*\"reflux\" + 0.000*\"sleep\" + '\n",
      "  '0.000*\"grade\" + 0.000*\"friend\" + 0.000*\"true\" + 0.000*\"navy\" + 0.000*\"bear\" '\n",
      "  '+ 0.000*\"middle\" + 0.000*\"bump\" + 0.000*\"potential\"'),\n",
      " (9,\n",
      "  '0.005*\"spot\" + 0.004*\"cell_phone\" + 0.004*\"bowel\" + 0.004*\"knee\" + '\n",
      "  '0.004*\"embarrassing\" + 0.003*\"frequently\" + 0.003*\"ready\" + 0.003*\"bottom\" '\n",
      "  '+ 0.003*\"nodule\" + 0.003*\"sir\" + 0.003*\"twice\" + 0.003*\"agree\" + '\n",
      "  '0.003*\"accord\" + 0.003*\"company\" + 0.003*\"everywhere\" + 0.003*\"eye\" + '\n",
      "  '0.003*\"approach\" + 0.002*\"wife\" + 0.002*\"perhaps\" + 0.002*\"implant\" + '\n",
      "  '0.002*\"line\" + 0.002*\"compromise\" + 0.002*\"bother\" + 0.002*\"anesthesia\" + '\n",
      "  '0.002*\"sliver\" + 0.002*\"mental\" + 0.002*\"diff\" + 0.002*\"digital\" + '\n",
      "  '0.002*\"building\" + 0.002*\"pole\" + 0.002*\"escort\" + 0.002*\"monitor\" + '\n",
      "  '0.002*\"tv\" + 0.002*\"coverage\" + 0.002*\"expensive\" + 0.002*\"thinking\" + '\n",
      "  '0.002*\"list\" + 0.002*\"electronic\" + 0.002*\"antenna\" + 0.002*\"apple\" + '\n",
      "  '0.002*\"damage\" + 0.002*\"confidence\" + 0.002*\"busy\" + 0.002*\"taking\" + '\n",
      "  '0.002*\"add\" + 0.002*\"split\" + 0.002*\"anxiety\" + 0.002*\"trigger\" + '\n",
      "  '0.002*\"alive\" + 0.002*\"favorable\"'),\n",
      " (10,\n",
      "  '0.000*\"bowel\" + 0.000*\"brachytherapy\" + 0.000*\"beam\" + '\n",
      "  '0.000*\"external_beam\" + 0.000*\"lymph_node\" + 0.000*\"recover\" + '\n",
      "  '0.000*\"erectile\" + 0.000*\"group\" + 0.000*\"implant\" + 0.000*\"urologist\" + '\n",
      "  '0.000*\"likelihood\" + 0.000*\"several\" + 0.000*\"radiate\" + 0.000*\"choose\" + '\n",
      "  '0.000*\"true\" + 0.000*\"surgical\" + 0.000*\"testosterone\" + 0.000*\"possible\" + '\n",
      "  '0.000*\"benefit\" + 0.000*\"needle\" + 0.000*\"outside\" + 0.000*\"robotic\" + '\n",
      "  '0.000*\"job\" + 0.000*\"approach\" + 0.000*\"necessarily\" + 0.000*\"figure\" + '\n",
      "  '0.000*\"deliver\" + 0.000*\"xray\" + 0.000*\"damage\" + 0.000*\"generally\" + '\n",
      "  '0.000*\"short\" + 0.000*\"outcome\" + 0.000*\"amount\" + 0.000*\"irritation\" + '\n",
      "  '0.000*\"level\" + 0.000*\"listen\" + 0.000*\"certain\" + 0.000*\"grade\" + '\n",
      "  '0.000*\"instance\" + 0.000*\"sexual\" + 0.000*\"datum\" + 0.000*\"rectal_exam\" + '\n",
      "  '0.000*\"compare\" + 0.000*\"drive\" + 0.000*\"external\" + 0.000*\"overall\" + '\n",
      "  '0.000*\"completely\" + 0.000*\"beacon\" + 0.000*\"step\" + 0.000*\"top\"'),\n",
      " (11,\n",
      "  '0.017*\"surveillance\" + 0.015*\"approach\" + 0.009*\"likelihood\" + '\n",
      "  '0.008*\"operation\" + 0.006*\"choose\" + 0.006*\"extensive\" + 0.006*\"diagnose\" + '\n",
      "  '0.005*\"grade\" + 0.004*\"sideeffect\" + 0.004*\"avoid\" + 0.004*\"potentially\" + '\n",
      "  '0.004*\"health\" + 0.004*\"potential\" + 0.004*\"benefit\" + 0.004*\"possible\" + '\n",
      "  '0.004*\"needle\" + 0.004*\"recover\" + 0.003*\"drive\" + 0.003*\"diagnosis\" + '\n",
      "  '0.003*\"examine\" + 0.003*\"manage\" + 0.003*\"discussion\" + 0.003*\"erectile\" + '\n",
      "  '0.003*\"baseline\" + 0.003*\"surgical\" + 0.003*\"evidence\" + '\n",
      "  '0.003*\"prostatectomy\" + 0.003*\"move_forward\" + 0.003*\"goal\" + 0.003*\"pill\" '\n",
      "  '+ 0.003*\"discuss\" + 0.003*\"focus\" + 0.003*\"line\" + 0.003*\"overall\" + '\n",
      "  '0.003*\"generally\" + 0.003*\"volume\" + 0.003*\"sexual\" + 0.003*\"tumor\" + '\n",
      "  '0.003*\"step\" + 0.003*\"outcome\" + 0.003*\"happy\" + 0.003*\"curative\" + '\n",
      "  '0.003*\"preference\" + 0.003*\"road\" + 0.002*\"rectal_exam\" + 0.002*\"pursue\" + '\n",
      "  '0.002*\"definitive\" + 0.002*\"robotic\" + 0.002*\"situation\" + 0.002*\"family\"')]\n"
     ]
    }
   ],
   "source": [
    "#print the top words used to form each topic\n",
    "print(\"DVD Topics:\")\n",
    "pprint(lda_model.print_topics(num_words=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Distributions by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_np)\n",
    "X['pred'] = y_pred\n",
    "X_0 = X[X.pred == 0]\n",
    "X_1 = X[X.pred == 1]\n",
    "X_0 = X_0[['c1_topic0', 'c1_topic1', 'c1_topic2', 'c1_topic3', 'c1_topic4', 'c1_topic5', 'c1_topic6', 'c1_topic7', 'c1_topic8', 'c1_topic9', 'c1_topic10', 'c1_topic11', 'c2_topic0', 'c2_topic1', 'c2_topic2', 'c2_topic3', 'c2_topic4', 'c2_topic5', 'c2_topic6', 'c2_topic7', 'c2_topic8', 'c2_topic9', 'c2_topic10', 'c2_topic11']]\n",
    "X_1 = X_1[['c1_topic0', 'c1_topic1', 'c1_topic2', 'c1_topic3', 'c1_topic4', 'c1_topic5', 'c1_topic6', 'c1_topic7', 'c1_topic8', 'c1_topic9', 'c1_topic10', 'c1_topic11', 'c2_topic0', 'c2_topic1', 'c2_topic2', 'c2_topic3', 'c2_topic4', 'c2_topic5', 'c2_topic6', 'c2_topic7', 'c2_topic8', 'c2_topic9', 'c2_topic10', 'c2_topic11']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.158864, 0.233513, 0.000000, 0.000000, 0.018667, 0.000000,\n",
       "       0.000000, 0.398491, 0.000000, 0.011411, 0.000000, 0.177052,\n",
       "       0.090767, 0.151919, 0.000000, 0.000000, 0.026933, 0.000000,\n",
       "       0.000000, 0.646902, 0.000000, 0.000000, 0.000000, 0.082709])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals_1 = X_1.mean().values # use to choose non-negligible topics for visualization\n",
    "vals_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19307265152205147, 0.3128256638917853, 0.35945929339447735, 0.09635433732696316, 0.09895522745353157, 0.6061195404255304, 0.05772495250878991]\n",
      "[0.15886403446824388, 0.23351348612200598, 0.3984910099413888, 0.1770519653078297, 0.09076719108576838, 0.6469017698576576, 0.08270879423147753]\n"
     ]
    }
   ],
   "source": [
    "vals_0 = X_0.mean().values\n",
    "vals_0 = [vals_0[0], vals_0[1], vals_0[7], vals_0[11], vals_0[12], vals_0[19], vals_0[23]]\n",
    "vals_1 = X_1.mean().values\n",
    "vals_1 = [vals_1[0], vals_1[1], vals_1[7], vals_1[11], vals_1[12], vals_1[19], vals_1[23]]\n",
    "print(vals_0)\n",
    "print(vals_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "[0.25, 1.25, 2.25, 3.25, 4.25, 5.25, 6.25]\n",
      "[0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3a6f6d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = ['C1 Topic 0', 'C1 Topic 1', 'C1 Topic 7', 'C1 Topic 11', 'C2 Topic 0', 'C2 Topic 7', 'C2 Topic 11']\n",
    "x_pos0 = [i for i, _ in enumerate(x)]\n",
    "x_pos1 = [i+0.25 for i in x_pos0]\n",
    "x_pos_middle = [i+0.1 for i in x_pos0]\n",
    "print(x_pos0)\n",
    "print(x_pos1)\n",
    "print(x_pos_middle)\n",
    "\n",
    "plt.bar(x_pos0, vals_0, color='orange',width=0.25)\n",
    "plt.bar(x_pos1, vals_1, color='blue', width=0.25)\n",
    "plt.ylabel(\"Average Topic Proportion\")\n",
    "plt.title(\"Average Topic Occurrences by Predicted Choice\")\n",
    "plt.xticks(x_pos_middle, x, rotation=60)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
